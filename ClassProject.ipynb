{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855b5262",
   "metadata": {},
   "source": [
    "# Data Science in Economics and Business - Class Project\n",
    "In this class project, you are supposed to work with GDP data taken from the International Monetary Fund."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290d39a",
   "metadata": {},
   "source": [
    "**IMPORTANT:** <br>\n",
    "Please enter the matriculation number of all group members here:\n",
    "1. XXXXXX\n",
    "2. YYYYYY\n",
    "3. ZZZZZZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c47bef",
   "metadata": {},
   "source": [
    "In this class project, you will use the different techniques taught in the course: data handling, data visualization, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96c71f",
   "metadata": {},
   "source": [
    "First load the necessary packages. <br>\n",
    "If you want to use additional libraries you can add them to the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8df249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import world_bank_data as wb\n",
    "import wbgapi as wba\n",
    "import datetime\n",
    "sns.set()\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import plotly.express as px\n",
    "import logging\n",
    "import country_converter as coco\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87d09d9",
   "metadata": {},
   "source": [
    "# Problem 1 - Data Handling\n",
    "The basis of your work will be the following GDP dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = pd.read_csv(\"GDP_IMF.csv\", sep=\";\")\n",
    "gdp.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d45b68",
   "metadata": {},
   "source": [
    "#### a)\n",
    "As you can see, there are many missing values in the data. <br>\n",
    "Before you can continue, you need to handle them. Proceed as follows:\n",
    "- Delete those countries with no data at all (if any)\n",
    "- Either delete the missing years for each country or use the years close by to approximate the missing value <br> *Example: Year 2004 is missing, but 2003 and 2005 are available; use the mean of GDP in 2003 and 2005 to replace missing year 2004.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413bcaca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = gdp.drop(gdp[gdp['year']>2022].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdp['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ca350",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_counts_country = gdp.groupby('Country')['GDP'].apply(lambda x: (x=='no data').sum())\n",
    "no_data_counts_country[no_data_counts_country > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b78044",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = gdp.drop(gdp[gdp['Country'].isin(no_data_counts_country[no_data_counts_country >= 8].index)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdp['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_counts_year = gdp.groupby('year')['GDP'].apply(lambda x: (x=='no data').sum())\n",
    "no_data_counts_year[no_data_counts_year > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34936963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'no data' with nan values and convert to float\n",
    "gdp['GDP'] = gdp['GDP'].replace('no data', np.nan).astype(float)\n",
    "\n",
    "# Set multi-index and sort\n",
    "gdp.set_index(['Country', 'year'], inplace=True)\n",
    "gdp.sort_index(inplace=True)\n",
    "\n",
    "# Generate a full index of all year combinations for each country\n",
    "all_years = range(gdp.index.get_level_values('year').min(), gdp.index.get_level_values('year').max() + 1)\n",
    "full_index = pd.MultiIndex.from_product([gdp.index.get_level_values('Country').unique(), all_years], \n",
    "                                        names=['Country', 'year'])\n",
    "\n",
    "# Reindex and interpolate\n",
    "gdp = gdp.reindex(full_index)\n",
    "gdp['GDP'] = gdp.groupby('Country', group_keys=False)['GDP'].apply(lambda group: group.interpolate(method='linear', limit_direction='both'))\n",
    "\n",
    "# Reset the index\n",
    "gdp.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c2032",
   "metadata": {},
   "source": [
    "#### b)\n",
    "We are only interested in the data on a country level and for years already passed. <br>\n",
    "The dataset, however, also contains information on whole regions such as the EU or G7. <br>\n",
    "It also contains predictions for GDP in the upcoming years. <br>\n",
    "Delete these observations from the data. <br>\n",
    "*Hint: Get a list of all unique values of the Country column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'Congo, Dem. Rep. of the': 'Democratic Republic of Congo',\n",
    "    'Congo, Republic of ': 'Republic of Congo',\n",
    "    'Taiwan Province of China': 'Taiwan SAR',\n",
    "    'Lao P.D.R.': 'Lao People\\'s Democratic Republic'\n",
    "}\n",
    "\n",
    "gdp['Country'] = gdp['Country'].replace(country_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp['Country'] = gdp['Country'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df83181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request\n",
    "response = requests.get('https://www.imf.org/en/Countries')\n",
    "\n",
    "# Parse the response content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the country names\n",
    "countries = [country.text for country in soup.select('a[href^=\"/en/Countries/\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab164b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = countries[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1011e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [c.replace('Congo, Democratic Republic of the', 'Democratic Republic of Congo') for c in countries]\n",
    "countries = [c.replace('Congo, Republic of', 'Republic of Congo') for c in countries]\n",
    "countries = [c.replace('Syrian Arab Republic', 'Syria') for c in countries]\n",
    "countries = [c.replace('Hong Kong Special Administrative Region', 'Hong Kong SAR') for c in countries]\n",
    "countries = [c.replace('Macao Special Administrative Region', 'Macao SAR') for c in countries]\n",
    "\n",
    "countries = [c.replace('North Macedonia', 'North Macedonia ') for c in countries]\n",
    "countries = [c.replace('Türkiye', 'Tuerkiye') for c in countries]\n",
    "countries = [c.replace('Côte d\\'Ivoire', 'Cote d\\'Ivoire') for c in countries]\n",
    "countries.append('Taiwan SAR')\n",
    "countries.append('Puerto Rico')\n",
    "countries.append('Saint Kitts and Nevis')\n",
    "countries.append('Saint Lucia')\n",
    "countries.append('Saint Vincent and the Grenadines')\n",
    "countries.append('Sao Tome und Principe')\n",
    "countries.append('West Bank and Gaza')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [country.split(',')[0] for country in countries]\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5466e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdp['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = gdp[~gdp['Country'].isin(countries)]\n",
    "\n",
    "for country in missing_countries['Country'].unique():\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = gdp[gdp['Country'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdp['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ef655",
   "metadata": {},
   "source": [
    "# Problem 2 - Data Visualization\n",
    "#### a)\n",
    "To get some first insights in the data, create meaningful plots. <br>\n",
    "You can use any kind that you deem useful: histograms, line plots, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f30f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plotly express to create an interactive scatter plot\n",
    "fig = px.scatter(gdp, x=gdp['year'], y=gdp['GDP'], color='Country', hover_name='Country')\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=f'Year',\n",
    "    yaxis_title=f'GDP',\n",
    "    title='Countries GDP in Billions [USD] (1992-2023)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cad71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(40, 8))\n",
    "sns.boxplot(x='Country', y='GDP', data=gdp)\n",
    "plt.title('Distribution of GDP Values for Each Country')\n",
    "plt.xticks(rotation=90) # This makes the country names vertical so they don't overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as clrs\n",
    "\n",
    "\n",
    "def heatmap_normal_scaling_ordered_alphabetical():\n",
    "    pivot_data = gdp.pivot(index='Country', columns='year', values='GDP')\n",
    "\n",
    "    plt.figure(figsize=(20, 40))  # Adjust the figure size as needed\n",
    "    sns.heatmap(pivot_data, cmap='YlGnBu', cbar_kws={\"shrink\": 0.3})\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Country')\n",
    "    plt.title('GDP Heatmap by Country and Year')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def heatmap_log_scaling_ordered_alphabetical():\n",
    "    pivot_data = gdp.pivot(index='Country', columns='year', values='GDP').fillna(0)\n",
    "\n",
    "    # Create a heatmap with log scaling for the legend\n",
    "    plt.figure(figsize=(20, 40))\n",
    "    sns.heatmap(pivot_data, cmap='YlGnBu', norm=clrs.LogNorm(vmin=1, vmax=pivot_data.values.max()), cbar_kws={\"shrink\": 0.3})\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Country')\n",
    "    plt.title('GDP Heatmap by Country and Year (Log Scaling)')\n",
    "\n",
    "\n",
    "def heatmap_log_scaling_ordered_gdp(): \n",
    "    pivot_data = gdp.pivot(index='Country', columns='year', values='GDP').fillna(0)\n",
    "\n",
    "    # Calculate the total GDP for each country and sort by GDP in descending order\n",
    "    total_gdp = pivot_data.sum(axis=1)\n",
    "    sorted_countries = total_gdp.sort_values(ascending=False).index\n",
    "\n",
    "    # Reorder the rows in the pivot_data DataFrame based on the sorted countries\n",
    "    pivot_data_sorted = pivot_data.loc[sorted_countries]\n",
    "\n",
    "    # Create a heatmap with log scaling for the legend\n",
    "    plt.figure(figsize=(20, 40))\n",
    "    sns.heatmap(pivot_data_sorted, cmap='YlGnBu', norm=clrs.LogNorm(vmin=1, vmax=pivot_data.values.max()), cbar_kws={\"shrink\": 0.3})\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Country')\n",
    "    plt.title('GDP Heatmap by Country and Year in Billions [USD] (Sorted by total GDP over time Descending)')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#heatmap_normal_scaling_ordered_alphabetical()\n",
    "#heatmap_log_scaling_ordered_alphabetical()\n",
    "heatmap_log_scaling_ordered_gdp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9348e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create a heatmap of the change in GDP from one year to the next for each country\n",
    "dfh = gdp\n",
    "# create a new column for the change in GDP from one year to the next\n",
    "dfh['gdp_change'] = dfh.groupby('Country')['GDP'].diff()\n",
    "dfh['gdp_change_category'] = np.where(dfh['gdp_change'] > 0, 'Increase', np.where(dfh['gdp_change'] < 0, 'Decrease', 'No Change'))\n",
    "\n",
    "# create a mapper to map the gdp_change_category column to numerical values\n",
    "mapper = {'Increase': 1, 'No Change': 0, 'Decrease': -1}\n",
    "\n",
    "# Map the gdp_change_category column to numerical values\n",
    "dfh['gdp_change_category'] = dfh['gdp_change_category'].map(mapper)\n",
    "\n",
    "# Pivot the DataFrame to have years as columns and countries as index\n",
    "df_pivot = dfh.pivot(index='Country', columns='year', values='gdp_change_category')\n",
    "\n",
    "# Create a colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['red', 'white', 'green'])\n",
    "\n",
    "\n",
    "## Calculate the absolute change in gdp from one year to the next as annotation for the heatmap\n",
    "# Pivot the data to have each country's GDP as a separate column\n",
    "pivot_data_labels = gdp.pivot(index='Country', columns='year', values='GDP')\n",
    "# Calculate the change in GDP for each country from one year to the next\n",
    "gdp_change_label = pivot_data_labels.diff(axis=1)\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(35, 40))\n",
    "sns.heatmap(df_pivot, annot=gdp_change_label, annot_kws={\"fontsize\":9}, cmap=cmap, cbar=False, linewidths=0.5, linecolor='lightgrey', fmt=\".2f\")\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Country')\n",
    "plt.title('GDP Change Heatmap in Billions [USD] (Green: Increase, Red: Decrease, White: No Change)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import bar_chart_race as bcr\n",
    "\n",
    "# Assuming you have already loaded the data into a DataFrame named 'data'\n",
    "# Let's say the columns are: 'Country', 'Year', 'GDP'\n",
    "\n",
    "# Pivot the data to have each country's GDP as a separate column\n",
    "pivot_data_race = gdp.pivot(index='Country', columns='year', values='GDP')\n",
    "pivot_data_race.columns = pd.to_datetime(pivot_data_race.columns, format='%Y')\n",
    "\n",
    "# Transpose the DataFrame to have years as columns and countries as rows\n",
    "pivot_data_race = pivot_data_race.T\n",
    "\n",
    "\n",
    "# Create the bar chart race animation\n",
    "bcr.bar_chart_race(\n",
    "    df=pivot_data_race,\n",
    "    filename='highest_gdp_comparison.gif',\n",
    "    orientation='h',       # Horizontal bars\n",
    "    sort='desc',           # Sort bars in descending order at each frame\n",
    "    n_bars=20,             # Number of bars (countries) to include in each frame\n",
    "    steps_per_period=10,   # Number of steps (frames) per year\n",
    "    period_length=500,     # Length of each period (milliseconds)\n",
    "    title='Top 20 Countries with Highest GDPs in Billions (USD) with median',\n",
    "    bar_label_size=7,      # Font size of bar labels\n",
    "    tick_label_size=7,     # Font size of tick labels\n",
    "    period_fmt='%Y',       # Show only the year for periodic steps\n",
    "    shared_fontdict={'family': 'Helvetica', 'color': '.1'},  # Font settings\n",
    "    filter_column_colors=True,  # Apply the color from the final frame to all frames\n",
    "    perpendicular_bar_func='median',  # Set the median as the reference line\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b1be1",
   "metadata": {},
   "source": [
    "![SegmentLocal](highest_gdp_comparison.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca73bd",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Pick a year with as little missing values as possible. <br>\n",
    "For this year, create an interactive map with `folium` that tells you the GDP in the country in the given year. <br>\n",
    "*Hint: Be cautious with country names.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_05 = gdp[gdp['year']==2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef707f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Initialize the geolocator\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Create a world map\n",
    "world_map= folium.Map(location=[10, -20], zoom_start=2.3)\n",
    "\n",
    "# Loop over each country and its GDP\n",
    "for idx, row in gdp_05.iterrows():\n",
    "    # Get the location of the country\n",
    "    location = geolocator.geocode(row['Country'])\n",
    "\n",
    "    # If the location is found\n",
    "    if location is not None:\n",
    "        # Add a marker to the map\n",
    "        folium.Marker(\n",
    "            location=[location.latitude, location.longitude], \n",
    "            popup=f\"Country: {row['Country']}, GDP: {row['GDP']}\",\n",
    "        ).add_to(world_map)\n",
    "\n",
    "# Show the map\n",
    "world_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a378e4e",
   "metadata": {},
   "source": [
    "# Problem 3 - Supervised Machine Learning\n",
    "#### a)\n",
    "First, try to predict the GDP in a given year and in a given country using the data from the past years. <br>\n",
    "Report the performance (measured in mean squared error) for different numbers of lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb362b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eccc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = gdp.drop(['gdp_change', 'gdp_change_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, country, model, lags):\n",
    "    df_country = df[df['Country']==country].drop('Country', axis=1)\n",
    "    df_country = df_country.sort_values(by='year').drop('year', axis=1)\n",
    "    for lag in range(1, lags+1):\n",
    "        df_country[f'GDP_lag_{lag}'] = df_country['GDP'].shift(lag)\n",
    "    \n",
    "    df_country = df_country.dropna()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_country.drop('GDP', axis=1),df_country['GDP'], test_size=.2,  shuffle=False)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    model.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373845c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "boost = AdaBoostRegressor(n_estimators=100, random_state=123)\n",
    "forest = RandomForestRegressor(n_estimators = 50, random_state=123)\n",
    "models = [linear, boost, forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for country in gdp['Country'].unique():\n",
    "    for lags in range (3, 6):\n",
    "        row = {'Country': country, 'lag': lags}\n",
    "        for model in models:\n",
    "            mse = train_model(gdp, country, model, lags)\n",
    "            results.append({'Country': country, 'lag': lags, 'model': type(model).__name__, 'mse': mse})\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_country = result_df.loc[result_df.groupby('Country')['mse'].idxmin()]\n",
    "best_models_per_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d6423",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Now, see if you can improve the prediction with additional data. <br>\n",
    "In this task, you are supposed to be creative and use your intuition. What could be important predictors? Think of, for example:\n",
    "- Country characteristics such as population, unemployment rates etc. <br> *Hint: You can search for official statistics, e.g., from OECD.*\n",
    "- Major historical events such as wars, natural disasters etc. <br> *Hint: You can make dummy variables if such an event happened for given country and year.*\n",
    "- Geographical information such as continent.\n",
    "\n",
    "*Note: It is well possible that you can't find data on very small countries. If you don't find data for some countries, you can drop them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = datetime.datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Little test with wbgapi, to build directly a dataframe\n",
    "# https://nbviewer.org/github/tgherzog/wbgapi/blob/master/examples/wbgapi-cookbook.ipynb\n",
    "#wba.data.DataFrame(['SP.POP.TOTL', 'NY.GDP.PCAP.CD'],\n",
    "#                  time=range(2010,2015), skipBlanks=True, columns='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get countries from World Bank API and drop unnecessary data\n",
    "countries = wb.get_countries()\n",
    "countries = countries[countries['incomeLevel'] != 'Aggregates'].rename(columns={'name': 'countryName'})\n",
    "countries.drop(['iso2Code', 'adminregion', 'capitalCity', 'lendingType', 'longitude', 'latitude'], axis=1, inplace=True)\n",
    "countries.reset_index(level=0, inplace=True)\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series_dict = {\n",
    "    #'Battle-related deaths (number of people)' : 'VC.BTL.DETH',\n",
    "    #'Droughts, floods, extreme temperatures' : 'EN.CLC.MDAT.ZS',\n",
    "    'Populalation (total)':'SP.POP.TOTL',\n",
    "    'Labor force (total)' : 'SL.TLF.TOTL.IN',\n",
    "    #'Real interest rate (%)':'FR.INR.RINR',                         #a lot worst performance\n",
    "    'Inflation, consumer prices (annual %)':'FP.CPI.TOTL.ZG',\n",
    "    'Imports of goods and services (in $)':'NE.IMP.GNFS.CD',\n",
    "    'Export of goods and services (in $)':'NE.EXP.GNFS.CD'\n",
    "\n",
    "\t\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for var_name, series_name in data_series_dict.items():\n",
    "    #Get series with the dict\n",
    "    data_series = wb.get_series(series_name, date='1992:'+str(current_year), id_or_value='id')\n",
    "\n",
    "    # Reset index, drop 'Series' column, and rename the series column\n",
    "    data_series_df = data_series.reset_index().drop(columns=['Series'])\n",
    "    data_series_df.rename(columns={series_name: var_name}, inplace=True)\n",
    "\n",
    "    # If result DataFrame is empty, copy the current data\n",
    "    if df.empty:\n",
    "        df = data_series_df.copy()\n",
    "    else:\n",
    "        # Otherwise merge current data with existing DataFrame\n",
    "        df = pd.merge(df, data_series_df, on=['Country', 'Year'], how='outer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge country information into the df\n",
    "df = pd.merge(df, countries, left_on='Country', right_on='id')\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "#df.set_index(['Country', 'Year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Battle-related deaths (number of people)'] = df['Battle-related deaths (number of people)'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71de4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Droughts, floods, extreme temperatures'] = df['Droughts, floods, extreme temperatures'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Real interest rate (%)'] = df.groupby('Country',group_keys=False)['Real interest rate (%)'].apply(lambda group: group.fillna(method='ffill'))\n",
    "df['Inflation, consumer prices (annual %)'] = df.groupby('Country',group_keys=False)['Inflation, consumer prices (annual %)'].apply(lambda group: group.fillna(method='ffill'))\n",
    "df['Labor force (total)'] = df.groupby('Country',group_keys=False)['Labor force (total)'].apply(lambda group: group.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08422",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_per_country = df.isnull().sum(axis=1).groupby(df['countryName']).sum()\n",
    "missing_values_per_country.sort_values(ascending=False, inplace=True)\n",
    "missing_values_per_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Real interest rate (%)'] = df.groupby('Country',group_keys=False)['Real interest rate (%)'].apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n",
    "df['Inflation, consumer prices (annual %)'] = df.groupby('Country',group_keys=False)['Inflation, consumer prices (annual %)'].apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n",
    "df['Labor force (total)'] = df.groupby('Country',group_keys=False)['Labor force (total)'].apply(lambda group: group.fillna(method='ffill').fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddf235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['Country'].isin(missing_values_per_country[missing_values_per_country > 8].index)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88480a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values.sort_values(ascending=False, inplace=True)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(missing_values[missing_values>500].index, axis=1)\n",
    "#df = df.groupby('Country').filter(lambda x: ~x.isnull().all().any())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_series_dict.keys():\n",
    "    print(column)\n",
    "    if column in df.columns:\n",
    "        print(column + ' inter')  # We don't want to interpolate the 'Country' column\n",
    "        df[column] = df.groupby('Country', group_keys=False)[column].apply(lambda group: group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any country that has a fully empty column, as we cant interpolate then.\n",
    "df = df.groupby('Country').filter(lambda x: ~x.isnull().all().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values.sort_values(ascending=False, inplace=True)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows containing at least one missing value\n",
    "missing_values_sample = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Display a sample of rows with missing values\n",
    "missing_values_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b80a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Countries to ISO3 to merge on later\n",
    "gdp['Country'] = gdp['Country'].replace('Tuerkiye', 'Turkey')\n",
    "converter = coco.CountryConverter()\n",
    "gdp['countryKey'] = gdp['Country'].apply(lambda x: converter.convert(names=x, to='ISO3'))\n",
    "gdp['Country'] = gdp['Country'].replace('Turkey', 'Tuerkiye')\n",
    "gdp.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Countries that where unable to match\n",
    "not_found = gdp[gdp['countryKey'] == 'not found']\n",
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdp['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the Countrys with the additional data\n",
    "df.rename(columns={'Country': 'countryKey'}, inplace=True)\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "gdp['year'] = gdp['year'].astype(int)\n",
    "merged = pd.merge(df, gdp, how='inner', left_on=['countryKey', 'Year'], right_on=['countryKey', 'year'])\n",
    "merged.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the lables as int\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "merged['region'] = le.fit_transform(merged.region.values)\n",
    "merged['incomeLevel'] = le.fit_transform(merged.incomeLevel.values)\n",
    "merged.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged.drop(columns=['countryKey', 'countryName', 'Year',  'region', 'incomeLevel'], axis=1, inplace=True)\n",
    "merged.drop(columns=['countryKey', 'countryName', 'Year'], axis=1, inplace=True)\n",
    "merged.rename(columns={'Year': 'year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae829b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.isnull().sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for country in merged['Country'].unique():\n",
    "    for lags in range (3, 6):\n",
    "        row = {'Country': country, 'lag': lags}\n",
    "        for model in models:\n",
    "            mse = train_model(merged, country, model, lags)\n",
    "            results.append({'Country': country, 'lag': lags, 'model': type(model).__name__, 'mse': mse})\n",
    "\n",
    "result_df_new = pd.DataFrame(results)\n",
    "\n",
    "result_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55026258",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_country_new = result_df_new.loc[result_df_new.groupby('Country')['mse'].idxmin()]\n",
    "best_models_per_country_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09901e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_country[best_models_per_country['Country']=='China']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_country_new[best_models_per_country_new['Country']=='China']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4244b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare the mse from each dataframe\n",
    "def compare_mse(row):\n",
    "    if row['mse_old'] < row['mse_new']:\n",
    "        return 0\n",
    "    elif row['mse_new'] < row['mse_old']:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "combined_df = best_models_per_country.merge(best_models_per_country_new, on='Country', suffixes=('_old', '_new'))\n",
    "\n",
    "# Apply comparison function and create new column\n",
    "combined_df['smaller_mse'] = combined_df.apply(compare_mse, axis=1)\n",
    "\n",
    "# Create resulting dataframe\n",
    "comparison_result = combined_df[['Country', 'smaller_mse', 'mse_old', 'mse_new']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_result['smaller_mse'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f116332",
   "metadata": {},
   "source": [
    "# Problem 4 - Unsupervised Machine Learning \n",
    "Use GDP and the information from Problem 3b) to cluster countries. <br>\n",
    "Which is the optimal number of clusters? <br>\n",
    "Can you provide an intuition for the clusters you identified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dab138",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68004adf",
   "metadata": {},
   "source": [
    "**Experiment 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the multi-index with 'Country' and 'year'\n",
    "df_pivoted = merged.set_index(['Country', 'year'])\n",
    "\n",
    "# Swap 'year' as a key level above the current columns\n",
    "df_pivoted = df_pivoted.unstack(level='year')\n",
    "\n",
    "# Swap the column names so that 'year' is on top\n",
    "df_pivoted.columns = df_pivoted.columns.swaplevel(0, 1)\n",
    "\n",
    "# Sort the columns in ascending order based on the 'year'\n",
    "df_pivoted = df_pivoted.sort_index(axis=1)\n",
    "\n",
    "# Display the DataFrame with the updated structure\n",
    "df_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Standardize the data before PCA and clustering\n",
    "#scaler = StandardScaler()\n",
    "#df_scaled = pd.DataFrame(scaler.fit_transform(df_pivoted), columns=df_pivoted.columns)\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "inertia_values = []\n",
    "max_clusters = 10\n",
    "for k in range(1, max_clusters + 1):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_pivoted)\n",
    "    inertia_values.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow graph to choose the optimal number of clusters (e.g., 3 or 4)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, max_clusters + 1), inertia_values, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia (Within-cluster Sum of Squares)')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e481996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimal number of clusters based on the elbow graph\n",
    "n_clusters = 3 # You can change this based on the elbow graph\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_pivoted['Cluster'] = kmeans.fit_predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96258bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_pivoted.values)\n",
    "df_pivoted[\"PC1\"] = pca_result[:,0]\n",
    "df_pivoted[\"PC2\"] = pca_result[:,1]\n",
    "df_pivoted[\"PC3\"] = pca_result[:,1]\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.figure(figsize=(8, 5))\n",
    "explained_variance_ratio_cumsum = pca.explained_variance_ratio_.cumsum()\n",
    "#plt.plot(range(1, len(explained_variance_ratio_cumsum)+1), explained_variance_ratio_cumsum, marker='o')\n",
    "plt.plot(range(1, len(explained_variance_ratio_cumsum)+1), explained_variance_ratio_cumsum, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Explained Variance Ratio for PCA')\n",
    "plt.xlim(1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive scatter plot using plotly\n",
    "fig = px.scatter_3d(df_pivoted, x='PC1', y='PC2',z='PC3', color='Cluster')\n",
    "fig.update_layout(showlegend=True)\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
